#!/usr/bin/env python3
"""
éªŒè¯ä¿®æ”¹åçš„Method5å¯å­¦ä¹ å‚æ•°
"""

import torch
import sys
sys.path.append('/home/kuangph/hf-starter')

def verify_method5_parameters():
    """éªŒè¯Method5çš„å¯å­¦ä¹ å‚æ•°"""
    print("=== Method5 å‚æ•°éªŒè¯ ===\n")
    
    from models.version4.Method5_v4 import Method5Config_v4, Method5LlamaForCausalLM_v4
    
    # åˆ›å»ºæ¨¡å‹
    config = Method5Config_v4(
        vocab_size=1000,
        hidden_size=128,
        intermediate_size=256,
        num_hidden_layers=3,
        num_attention_heads=4,
        max_position_embeddings=512
    )
    
    model = Method5LlamaForCausalLM_v4(config)
    
    # æ£€æŸ¥å‚æ•°
    print("ğŸ” æ£€æŸ¥å¯å­¦ä¹ å‚æ•°:")
    scaling_params = []
    for name, param in model.named_parameters():
        if 'score_params' in name:
            scaling_params.append((name, param))
            print(f"  æ‰¾åˆ°å‚æ•°: {name}, shape: {param.shape}")
    
    print(f"\nğŸ“Š æ€»å…±æ‰¾åˆ° {len(scaling_params)} ä¸ªscore_params")
    
    # æµ‹è¯•æ¢¯åº¦
    print("\nğŸ”„ æµ‹è¯•æ¢¯åº¦è®¡ç®—:")
    model.train()
    
    # å‰å‘ä¼ æ’­
    input_ids = torch.randint(0, config.vocab_size, (2, 32))
    outputs = model(input_ids, labels=input_ids)
    loss = outputs.loss
    
    # åå‘ä¼ æ’­
    loss.backward()
    
    grad_count = 0
    for name, param in scaling_params:
        if param.grad is not None:
            grad_norm = param.grad.norm().item()
            print(f"  {name}: grad_norm = {grad_norm:.6f}")
            grad_count += 1
        else:
            print(f"  {name}: âŒ æ²¡æœ‰æ¢¯åº¦")
    
    if grad_count == len(scaling_params):
        print("âœ… æ‰€æœ‰å‚æ•°éƒ½æœ‰æ¢¯åº¦")
    else:
        print("âŒ éƒ¨åˆ†å‚æ•°æ²¡æœ‰æ¢¯åº¦")
    
    # æµ‹è¯•çº¦æŸæ¡ä»¶
    print("\nğŸ“ éªŒè¯çº¦æŸæ¡ä»¶:")
    for layer_idx in range(config.num_hidden_layers):
        layer = model.model.layers[layer_idx]
        scaling_module = layer.self_attn.modified_scaling
        
        scores = scaling_module.score_params.data
        softmax_weights = torch.softmax(scores, dim=0)
        a_params = softmax_weights * len(scores)
        
        constraint_satisfied = abs(a_params.sum().item() - len(scores)) < 1e-6
        print(f"  Layer {layer_idx}: sum(a_params) = {a_params.sum().item():.6f}, çº¦æŸæ»¡è¶³: {constraint_satisfied}")
    
    print("\nâœ… Method5éªŒè¯å®Œæˆï¼")

if __name__ == "__main__":
    verify_method5_parameters()
