#!/usr/bin/env python3
"""
æµ‹è¯•Version4æ–¹æ³•çš„å¯å­¦ä¹ å‚æ•°ä¿å­˜åŠŸèƒ½
"""

import torch
import sys
import tempfile
import os
import json
sys.path.append('/home/kuangph/hf-starter')

def test_method_parameter_saving():
    """æµ‹è¯•æ‰€æœ‰Version4æ–¹æ³•çš„å‚æ•°ä¿å­˜åŠŸèƒ½"""
    print("=== Version4 å¯å­¦ä¹ å‚æ•°ä¿å­˜æµ‹è¯• ===\n")
    
    methods_info = [
        ("Method4", "models.version4.Method4_v4", "Method4Config_v4", "Method4LlamaForCausalLM_v4"),
        ("Method5", "models.version4.Method5_v4", "Method5Config_v4", "Method5LlamaForCausalLM_v4"),
        ("Method6", "models.version4.Method6_v4", "Method6Config_v4", "Method6LlamaForCausalLM_v4"),
        ("Method7", "models.version4.Method7_v4", "Method7Config_v4", "Method7LlamaForCausalLM_v4"),
    ]
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    print(f"ä¸´æ—¶ç›®å½•: {temp_dir}\n")
    
    all_passed = True
    
    for method_name, module_path, config_class_name, model_class_name in methods_info:
        try:
            print(f"ğŸ§ª æµ‹è¯• {method_name}:")
            
            # åŠ¨æ€å¯¼å…¥
            module = __import__(module_path, fromlist=[config_class_name, model_class_name])
            config_class = getattr(module, config_class_name)
            model_class = getattr(module, model_class_name)
            
            # åˆ›å»ºå°å‹æµ‹è¯•é…ç½®
            config = config_class(
                vocab_size=1000,
                hidden_size=128,
                intermediate_size=256,
                num_hidden_layers=3,  # åªç”¨3å±‚è¿›è¡Œæµ‹è¯•
                num_attention_heads=4,
                max_position_embeddings=512
            )
            
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            model = model_class(config)
            
            # æµ‹è¯•get_all_layer_weightsæ–¹æ³•
            if hasattr(model, 'get_all_layer_weights'):
                weights = model.get_all_layer_weights()
                print(f"  âœ… get_all_layer_weights: æˆåŠŸï¼Œè¿”å›{len(weights)}å±‚æƒé‡")
                
                # æ£€æŸ¥æƒé‡æ ¼å¼
                for i, layer_weight in enumerate(weights):
                    if isinstance(layer_weight, dict):
                        if layer_weight:  # éç©ºå­—å…¸
                            param_info = []
                            for param_name, param_tensor in layer_weight.items():
                                if hasattr(param_tensor, 'shape'):
                                    if param_tensor.numel() == 1:  # æ ‡é‡
                                        param_info.append(f"{param_name}(scalar)")
                                    else:
                                        param_info.append(f"{param_name}({list(param_tensor.shape)})")
                            print(f"    Layer {i}: {', '.join(param_info)}")
                        else:
                            print(f"    Layer {i}: empty dict")
                    elif hasattr(layer_weight, '__len__') and len(layer_weight) > 0:
                        print(f"    Layer {i}: vector length {len(layer_weight)}")
                    elif hasattr(layer_weight, 'numel') and layer_weight.numel() == 0:
                        print(f"    Layer {i}: empty tensor")
                    else:
                        print(f"    Layer {i}: unknown format")
                
            else:
                print(f"  âŒ get_all_layer_weights: æ–¹æ³•ä¸å­˜åœ¨")
                all_passed = False
                continue
            
            # æµ‹è¯•save_learned_parametersæ–¹æ³•
            if hasattr(model, 'save_learned_parameters'):
                save_path = model.save_learned_parameters(temp_dir)
                print(f"  âœ… save_learned_parameters: æˆåŠŸï¼Œä¿å­˜åˆ° {os.path.basename(save_path)}")
                
                # éªŒè¯æ–‡ä»¶å­˜åœ¨å¹¶å¯è¯»å–
                if os.path.exists(save_path):
                    with open(save_path, 'r') as f:
                        saved_data = json.load(f)
                    print(f"    JSONæ–‡ä»¶åŒ…å« {len(saved_data)} å±‚æ•°æ®")
                    
                    # æ£€æŸ¥ç»Ÿè®¡æ–‡ä»¶
                    stats_path = save_path.replace('.json', '_stats.txt')
                    if os.path.exists(stats_path):
                        print(f"    âœ… ç»Ÿè®¡æ–‡ä»¶ä¹Ÿå·²ç”Ÿæˆ")
                    else:
                        print(f"    âš ï¸  ç»Ÿè®¡æ–‡ä»¶æœªç”Ÿæˆ")
                        
                else:
                    print(f"  âŒ ä¿å­˜çš„æ–‡ä»¶ä¸å­˜åœ¨")
                    all_passed = False
                    
            else:
                print(f"  âŒ save_learned_parameters: æ–¹æ³•ä¸å­˜åœ¨")
                all_passed = False
                
            print()
                
        except Exception as e:
            print(f"  âŒ {method_name} æµ‹è¯•å¤±è´¥: {str(e)}")
            all_passed = False
            print()
    
    # æ¸…ç†ä¸´æ—¶ç›®å½•
    import shutil
    shutil.rmtree(temp_dir)
    
    print("=" * 50)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰Version4æ–¹æ³•çš„å‚æ•°ä¿å­˜åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("\nâœ… åŠŸèƒ½ç¡®è®¤:")
        print("- Method4: ä¿å­˜aå’Œbå‚æ•° (æ ‡é‡)")
        print("- Method5: ä¿å­˜a_paramså‘é‡")
        print("- Method6: ä¿å­˜a_paramså’Œb_paramså‘é‡")
        print("- Method7: ä¿å­˜a_paramså‘é‡")
        print("\nğŸš€ ready for training with parameter saving!")
    else:
        print("âŒ éƒ¨åˆ†æ–¹æ³•æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å®ç°")
    
    return all_passed

def test_runclm_integration():
    """æµ‹è¯•ä¸run_clm.pyçš„é›†æˆ"""
    print("\n=== run_clm.py é›†æˆæµ‹è¯• ===\n")
    
    # æ¨¡æ‹Ÿæ£€æµ‹é€»è¾‘
    test_cases = [
        "Method4LlamaForCausalLM_v4",
        "Method5LlamaForCausalLM_v4", 
        "Method6LlamaForCausalLM_v4",
        "Method7LlamaForCausalLM_v4",
        "Method1LlamaForCausalLM_v4",  # åº”è¯¥è¢«è·³è¿‡
        "OtherModel"  # åº”è¯¥è¢«è·³è¿‡
    ]
    
    expected_detections = [
        ("Method4LlamaForCausalLM_v4", True),
        ("Method5LlamaForCausalLM_v4", True),
        ("Method6LlamaForCausalLM_v4", True), 
        ("Method7LlamaForCausalLM_v4", True),
        ("Method1LlamaForCausalLM_v4", False),
        ("OtherModel", False)
    ]
    
    print("æ¨¡æ‹Ÿrun_clm.pyä¸­çš„æ£€æµ‹é€»è¾‘:")
    for model_name, should_detect in expected_detections:
        is_v4_method = any(method in model_name for method in ["Method4LlamaForCausalLM_v4", "Method5LlamaForCausalLM_v4", "Method6LlamaForCausalLM_v4", "Method7LlamaForCausalLM_v4"])
        
        if is_v4_method == should_detect:
            print(f"  âœ… {model_name}: {'æ£€æµ‹åˆ°' if should_detect else 'è·³è¿‡'}")
        else:
            print(f"  âŒ {model_name}: æ£€æµ‹é€»è¾‘é”™è¯¯")
    
    print("\nğŸ”§ run_clm.py æ›´æ–°å†…å®¹:")
    print("- æ·»åŠ äº†Version4æ–¹æ³•çš„ä¸“ç”¨æ£€æµ‹é€»è¾‘")
    print("- æ”¯æŒè°ƒç”¨å„æ–¹æ³•çš„save_learned_parametersæ–¹æ³•")
    print("- ä¿æŒå¯¹Version3æ–¹æ³•çš„å‘åå…¼å®¹")

if __name__ == "__main__":
    success = test_method_parameter_saving()
    test_runclm_integration()
    
    if success:
        print("\n" + "="*60)
        print("ğŸ¯ Version4å¯å­¦ä¹ å‚æ•°ä¿å­˜åŠŸèƒ½å®Œå…¨å°±ç»ªï¼")
        print("âœ¨ åŠŸèƒ½ç‰¹ç‚¹:")
        print("- æ¯ä¸ªæ–¹æ³•éƒ½æœ‰ä¸“ç”¨çš„å‚æ•°ä¿å­˜æ ¼å¼")
        print("- ç”Ÿæˆè¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯æ–‡ä»¶")
        print("- ä¸run_clm.pyå®Œå…¨é›†æˆ")
        print("- è‡ªåŠ¨æ£€æµ‹å¹¶ä¿å­˜ç›¸åº”å‚æ•°")
        print("\nğŸš€ å¯ä»¥å¼€å§‹è®­ç»ƒå¹¶è‡ªåŠ¨ä¿å­˜å¯å­¦ä¹ å‚æ•°ï¼")
        print("="*60)
