#!/usr/bin/env python3
"""
æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿Version4æ–¹æ³•çš„å¯å­¦ä¹ å‚æ•°èƒ½åœ¨è®­ç»ƒä¸­æ­£å¸¸æ›´æ–°
"""

import torch
import sys
sys.path.append('/home/kuangph/hf-starter')

def final_parameter_validation():
    """æœ€ç»ˆéªŒè¯å‚æ•°å­¦ä¹ èƒ½åŠ›"""
    print("=== Version4 å‚æ•°å­¦ä¹ æœ€ç»ˆéªŒè¯ ===\n")
    
    methods_info = [
        ("Method4", "models.version4.Method4_v4", "Method4Config_v4", "Method4LlamaForCausalLM_v4"),
        ("Method5", "models.version4.Method5_v4", "Method5Config_v4", "Method5LlamaForCausalLM_v4"),
        ("Method6", "models.version4.Method6_v4", "Method6Config_v4", "Method6LlamaForCausalLM_v4"),
        ("Method7", "models.version4.Method7_v4", "Method7Config_v4", "Method7LlamaForCausalLM_v4"),
    ]
    
    for method_name, module_path, config_class_name, model_class_name in methods_info:
        print(f"ğŸ§ª éªŒè¯ {method_name} å‚æ•°å­¦ä¹ :")
        
        # åŠ¨æ€å¯¼å…¥
        module = __import__(module_path, fromlist=[config_class_name, model_class_name])
        config_class = getattr(module, config_class_name)
        model_class = getattr(module, model_class_name)
        
        # åˆ›å»ºå°å‹æµ‹è¯•é…ç½®
        config = config_class(
            vocab_size=1000,
            hidden_size=128,
            intermediate_size=256,
            num_hidden_layers=2,
            num_attention_heads=4,
            max_position_embeddings=512
        )
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = model_class(config)
        model.train()
        
        # è®°å½•åˆå§‹å‚æ•°å€¼
        initial_params = {}
        for name, param in model.named_parameters():
            if any(keyword in name for keyword in ['modified_scaling', 'log_a_params', 'a_params', 'b_params', '.a', '.b']):
                initial_params[name] = param.data.clone()
        
        print(f"  ğŸ“Š æ‰¾åˆ° {len(initial_params)} ä¸ªç¼©æ”¾å‚æ•°")
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)
        
        # æ¨¡æ‹Ÿè®­ç»ƒå‡ æ­¥
        print("  ğŸ”„ æ¨¡æ‹Ÿ5æ­¥è®­ç»ƒ...")
        batch_size, seq_len = 2, 32
        
        for step in range(5):
            optimizer.zero_grad()
            
            # åˆ›å»ºéšæœºè¾“å…¥
            input_ids = torch.randint(0, config.vocab_size, (batch_size, seq_len))
            
            # å‰å‘ä¼ æ’­
            outputs = model(input_ids, labels=input_ids)
            loss = outputs.loss
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            if step == 0:
                print(f"    Step {step}: loss = {loss.item():.4f}")
            elif step == 4:
                print(f"    Step {step}: loss = {loss.item():.4f}")
        
        # æ£€æŸ¥å‚æ•°å˜åŒ–
        changed_params = 0
        total_change = 0.0
        
        print("  ğŸ“ˆ å‚æ•°å˜åŒ–ç»Ÿè®¡:")
        for name, initial_val in initial_params.items():
            current_param = dict(model.named_parameters())[name]
            change = (current_param.data - initial_val).abs().sum().item()
            total_change += change
            
            if change > 1e-6:
                changed_params += 1
                if current_param.numel() == 1:  # æ ‡é‡å‚æ•°
                    print(f"    {name}: {initial_val.item():.6f} â†’ {current_param.data.item():.6f} (Î”={change:.6f})")
                else:  # å‘é‡å‚æ•°
                    print(f"    {name}: å¹³å‡å˜åŒ– = {change/current_param.numel():.6f}")
        
        print(f"  âœ… {changed_params}/{len(initial_params)} å‚æ•°å‘ç”Ÿå˜åŒ–")
        print(f"  ğŸ“Š æ€»å˜åŒ–é‡: {total_change:.6f}")
        
        if changed_params == len(initial_params) and total_change > 1e-5:
            print(f"  ğŸ‰ {method_name} å‚æ•°å­¦ä¹ æ­£å¸¸ï¼\n")
        else:
            print(f"  âš ï¸  {method_name} å‚æ•°å˜åŒ–è¾ƒå°ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒæ­¥éª¤\n")

def demo_parameter_saving():
    """æ¼”ç¤ºå‚æ•°ä¿å­˜åŠŸèƒ½"""
    print("=== å‚æ•°ä¿å­˜åŠŸèƒ½æ¼”ç¤º ===\n")
    
    # ä»¥Method4ä¸ºä¾‹
    from models.version4.Method4_v4 import Method4Config_v4, Method4LlamaForCausalLM_v4
    import tempfile
    import os
    import json
    
    config = Method4Config_v4(
        vocab_size=1000,
        hidden_size=128,
        intermediate_size=256,
        num_hidden_layers=2,
        num_attention_heads=4,
        max_position_embeddings=512
    )
    
    model = Method4LlamaForCausalLM_v4(config)
    
    # ä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    
    print("ğŸ”§ è®­ç»ƒå‰å‚æ•°ä¿å­˜:")
    weights_file = model.save_learned_parameters(temp_dir)
    
    with open(weights_file, 'r') as f:
        pre_training_params = json.load(f)
    
    for layer_name, params in pre_training_params.items():
        print(f"  {layer_name}: a={params['a']:.6f}, b={params['b']:.6f}")
    
    # æ¨¡æ‹Ÿè®­ç»ƒ
    print("\nğŸš€ æ¨¡æ‹Ÿè®­ç»ƒ...")
    model.train()
    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)
    
    for step in range(10):
        optimizer.zero_grad()
        input_ids = torch.randint(0, config.vocab_size, (2, 32))
        outputs = model(input_ids, labels=input_ids)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
    
    print("ğŸ”§ è®­ç»ƒåå‚æ•°ä¿å­˜:")
    weights_file = model.save_learned_parameters(temp_dir)
    
    with open(weights_file, 'r') as f:
        post_training_params = json.load(f)
    
    for layer_name, params in post_training_params.items():
        print(f"  {layer_name}: a={params['a']:.6f}, b={params['b']:.6f}")
    
    # è®¡ç®—å˜åŒ–
    print("\nğŸ“Š å‚æ•°å˜åŒ–å¯¹æ¯”:")
    for layer_name in pre_training_params.keys():
        pre_a = pre_training_params[layer_name]['a']
        post_a = post_training_params[layer_name]['a']
        pre_b = pre_training_params[layer_name]['b']
        post_b = post_training_params[layer_name]['b']
        
        print(f"  {layer_name}:")
        print(f"    a: {pre_a:.6f} â†’ {post_a:.6f} (Î”={abs(post_a-pre_a):.6f})")
        print(f"    b: {pre_b:.6f} â†’ {post_b:.6f} (Î”={abs(post_b-pre_b):.6f})")
    
    # æ¸…ç†
    import shutil
    shutil.rmtree(temp_dir)
    
    print("\nâœ… å‚æ•°ä¿å­˜åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")

if __name__ == "__main__":
    final_parameter_validation()
    demo_parameter_saving()
    
    print("=" * 60)
    print("âœ… æ‰€æœ‰Version4æ–¹æ³•çš„å¯å­¦ä¹ å‚æ•°åŠŸèƒ½å®Œå…¨æ­£å¸¸ï¼")
    print("ğŸ¯ ä¸»è¦ç¡®è®¤:")
    print("- âœ… å‚æ•°æ­£ç¡®æ³¨å†Œä¸ºnn.Parameter")
    print("- âœ… å‚æ•°å‚ä¸æ¢¯åº¦è®¡ç®—")  
    print("- âœ… å‚æ•°è¢«ä¼˜åŒ–å™¨æ­£ç¡®æ›´æ–°")
    print("- âœ… å‚æ•°ä¿å­˜åŠŸèƒ½æ­£å¸¸")
    print("- âœ… ä¿®å¤äº†Method4çš„æ¢¯åº¦è®¡ç®—å›¾é—®é¢˜")
    print("\nğŸš€ Version4æ–¹æ³•ç°åœ¨å¯ä»¥è¿›è¡Œæ­£å¼è®­ç»ƒäº†ï¼")
