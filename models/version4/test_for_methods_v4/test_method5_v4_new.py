#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®æ”¹åçš„Method5å®ç°ï¼šçº¦æŸa_1 + a_2 + ... + a_m = m
"""

import torch
import sys
import math
sys.path.append('/home/kuangph/hf-starter')

def test_method5_constraint():
    """æµ‹è¯•Method5çš„çº¦æŸæ¡ä»¶"""
    print("=== Method5 çº¦æŸæ¡ä»¶æµ‹è¯• ===\n")
    
    from models.version4.Method5_v4 import Method5Config_v4, Method5LlamaForCausalLM_v4
    
    # åˆ›å»ºå°å‹æµ‹è¯•é…ç½®
    config = Method5Config_v4(
        vocab_size=1000,
        hidden_size=128,
        intermediate_size=256,
        num_hidden_layers=4,
        num_attention_heads=4,
        max_position_embeddings=512
    )
    
    model = Method5LlamaForCausalLM_v4(config)
    head_dim = config.hidden_size // config.num_attention_heads
    
    print(f"ğŸ“Š æ¨¡å‹é…ç½®: {config.num_hidden_layers}å±‚, head_dim={head_dim}")
    print()
    
    # æµ‹è¯•æ¯å±‚çš„çº¦æŸæ¡ä»¶
    for layer_idx in range(config.num_hidden_layers):
        layer = model.model.layers[layer_idx]
        scaling_module = layer.self_attn.modified_scaling
        
        print(f"ğŸ” æµ‹è¯•ç¬¬{layer_idx}å±‚:")
        print(f"  æœŸæœ›å‘é‡é•¿åº¦: {layer_idx + 1}")
        print(f"  å®é™…score_paramsé•¿åº¦: {len(scaling_module.score_params)}")
        
        # æ£€æŸ¥åˆå§‹çš„score_params
        initial_scores = scaling_module.score_params.data.clone()
        print(f"  åˆå§‹scores: {initial_scores.tolist()}")
        
        # è®¡ç®—å¯¹åº”çš„a_params
        num_matrices = layer_idx + 1
        softmax_weights = torch.softmax(initial_scores, dim=0)
        a_params = softmax_weights * num_matrices
        
        print(f"  Softmaxæƒé‡: {softmax_weights.tolist()}")
        print(f"  Aå‚æ•°: {a_params.tolist()}")
        print(f"  Aå‚æ•°ä¹‹å’Œ: {a_params.sum().item():.6f} (åº”è¯¥ä¸º {num_matrices})")
        
        # éªŒè¯çº¦æŸæ¡ä»¶
        constraint_satisfied = abs(a_params.sum().item() - num_matrices) < 1e-6
        print(f"  âœ… çº¦æŸæ¡ä»¶æ»¡è¶³: {constraint_satisfied}")
        
        # æ¨¡æ‹Ÿä¸€äº›QKçŸ©é˜µæ¥æµ‹è¯•ç¼©æ”¾è®¡ç®—
        batch_size, num_heads, seq_len = 2, 4, 10
        qk_matrices = []
        for i in range(num_matrices):
            qk_matrix = torch.randn(batch_size, num_heads, seq_len, seq_len)
            qk_matrices.append(qk_matrix)
        
        # æµ‹è¯•ç¼©æ”¾è®¡ç®—
        result = scaling_module.compute_modified_scaling(qk_matrices, layer_idx)
        print(f"  ç¼©æ”¾è®¡ç®—ç»“æœå½¢çŠ¶: {result.shape}")
        
        # éªŒè¯ç¼©æ”¾å‘é‡çš„è®¡ç®—
        expected_scaling_vector = a_params / math.sqrt(head_dim)
        print(f"  æœŸæœ›ç¼©æ”¾å‘é‡: {expected_scaling_vector.tolist()}")
        print(f"  ç¼©æ”¾å‘é‡æ€»å’Œ/sqrt(d_k): {expected_scaling_vector.sum().item():.6f}")
        print()

def test_method5_training():
    """æµ‹è¯•Method5åœ¨è®­ç»ƒä¸­çš„å‚æ•°æ›´æ–°"""
    print("=== Method5 è®­ç»ƒæµ‹è¯• ===\n")
    
    from models.version4.Method5_v4 import Method5Config_v4, Method5LlamaForCausalLM_v4
    
    config = Method5Config_v4(
        vocab_size=1000,
        hidden_size=128,
        intermediate_size=256,
        num_hidden_layers=3,
        num_attention_heads=4,
        max_position_embeddings=512
    )
    
    model = Method5LlamaForCausalLM_v4(config)
    model.train()
    
    # è®°å½•åˆå§‹å‚æ•°
    print("ğŸ“‹ è®­ç»ƒå‰å‚æ•°çŠ¶æ€:")
    initial_params = {}
    for layer_idx in range(config.num_hidden_layers):
        scaling_module = model.model.layers[layer_idx].self_attn.modified_scaling
        scores = scaling_module.score_params.data.clone()
        softmax_weights = torch.softmax(scores, dim=0)
        a_params = softmax_weights * (layer_idx + 1)
        
        initial_params[layer_idx] = {
            'scores': scores.clone(),
            'a_params': a_params.clone()
        }
        
        print(f"  Layer {layer_idx}: scores={scores.tolist()}")
        print(f"  Layer {layer_idx}: a_params={a_params.tolist()} (sum={a_params.sum():.6f})")
    
    # æ¨¡æ‹Ÿè®­ç»ƒ
    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)
    
    print("\nğŸš€ å¼€å§‹æ¨¡æ‹Ÿè®­ç»ƒ...")
    for step in range(5):
        optimizer.zero_grad()
        
        # åˆ›å»ºéšæœºè¾“å…¥
        input_ids = torch.randint(0, config.vocab_size, (2, 32))
        outputs = model(input_ids, labels=input_ids)
        loss = outputs.loss
        
        loss.backward()
        optimizer.step()
        
        if step == 0 or step == 4:
            print(f"  Step {step}: loss = {loss.item():.4f}")
    
    # æ£€æŸ¥è®­ç»ƒåçš„å‚æ•°
    print("\nğŸ“‹ è®­ç»ƒåå‚æ•°çŠ¶æ€:")
    for layer_idx in range(config.num_hidden_layers):
        scaling_module = model.model.layers[layer_idx].self_attn.modified_scaling
        scores = scaling_module.score_params.data
        softmax_weights = torch.softmax(scores, dim=0)
        a_params = softmax_weights * (layer_idx + 1)
        
        initial_scores = initial_params[layer_idx]['scores']
        initial_a_params = initial_params[layer_idx]['a_params']
        
        score_change = (scores - initial_scores).abs().sum().item()
        a_change = (a_params - initial_a_params).abs().sum().item()
        
        print(f"  Layer {layer_idx}: scores={scores.tolist()}")
        print(f"  Layer {layer_idx}: a_params={a_params.tolist()} (sum={a_params.sum():.6f})")
        print(f"  Layer {layer_idx}: scoreå˜åŒ–={score_change:.6f}, aå‚æ•°å˜åŒ–={a_change:.6f}")
        
        # éªŒè¯çº¦æŸæ¡ä»¶ä»ç„¶æ»¡è¶³
        constraint_satisfied = abs(a_params.sum().item() - (layer_idx + 1)) < 1e-6
        print(f"  Layer {layer_idx}: âœ… çº¦æŸæ¡ä»¶æ»¡è¶³: {constraint_satisfied}")
        print()

def test_parameter_saving():
    """æµ‹è¯•å‚æ•°ä¿å­˜åŠŸèƒ½"""
    print("=== Method5 å‚æ•°ä¿å­˜æµ‹è¯• ===\n")
    
    from models.version4.Method5_v4 import Method5Config_v4, Method5LlamaForCausalLM_v4
    import tempfile
    import json
    import os
    
    config = Method5Config_v4(
        vocab_size=1000,
        hidden_size=128,
        intermediate_size=256,
        num_hidden_layers=3,
        num_attention_heads=4,
        max_position_embeddings=512
    )
    
    model = Method5LlamaForCausalLM_v4(config)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    
    # æµ‹è¯•å‚æ•°è·å–
    all_weights = model.get_all_layer_weights()
    print(f"ğŸ“Š è·å–åˆ° {len(all_weights)} å±‚å‚æ•°")
    
    for layer_idx, layer_weights in enumerate(all_weights):
        if layer_weights:
            scores = layer_weights['score_params']
            a_params = layer_weights['a_params']
            print(f"  Layer {layer_idx}: scoreé•¿åº¦={len(scores)}, aå‚æ•°é•¿åº¦={len(a_params)}")
            print(f"  Layer {layer_idx}: aå‚æ•°å’Œ={sum(a_params):.6f}")
    
    # æµ‹è¯•å‚æ•°ä¿å­˜
    weights_file = model.save_learned_parameters(temp_dir)
    print(f"\nğŸ“ å‚æ•°ä¿å­˜åˆ°: {os.path.basename(weights_file)}")
    
    # éªŒè¯ä¿å­˜çš„æ–‡ä»¶
    with open(weights_file, 'r') as f:
        saved_data = json.load(f)
    
    print(f"ğŸ“‹ JSONæ–‡ä»¶åŒ…å« {len(saved_data)} å±‚æ•°æ®")
    for layer_name, layer_data in saved_data.items():
        print(f"  {layer_name}: {list(layer_data.keys())}")
    
    # æ£€æŸ¥ç»Ÿè®¡æ–‡ä»¶
    stats_file = weights_file.replace('.json', '_stats.txt')
    if os.path.exists(stats_file):
        print(f"âœ… ç»Ÿè®¡æ–‡ä»¶ä¹Ÿå·²ç”Ÿæˆ: {os.path.basename(stats_file)}")
    
    # æ¸…ç†
    import shutil
    shutil.rmtree(temp_dir)
    
    print("âœ… å‚æ•°ä¿å­˜æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_method5_constraint()
    test_method5_training()
    test_parameter_saving()
    
    print("=" * 60)
    print("ğŸ‰ Method5ä¿®æ”¹éªŒè¯å®Œæˆï¼")
    print("\nâœ… ä¸»è¦æ”¹è¿›:")
    print("- ç¼©æ”¾ä» 1/(a_i*sqrt(d_k)) æ”¹ä¸º a_i/sqrt(d_k)")
    print("- æ·»åŠ çº¦æŸæ¡ä»¶: a_1 + a_2 + ... + a_m = m")
    print("- é€šè¿‡softmaxå®ç°çº¦æŸ: scores â†’ softmax â†’ *m â†’ a_params")
    print("- å‚æ•°ä¿å­˜åŒ…å«åŸå§‹scoreså’Œæœ€ç»ˆa_params")
    print("\nğŸš€ Method5å·²å‡†å¤‡å¥½ç”¨äºè®­ç»ƒï¼")
