#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„Version4æ–¹æ³• - éªŒè¯æ¯å±‚ç‹¬ç«‹çš„å¯å­¦ä¹ å‚æ•°è®¾è®¡
"""

import math
import torch
import sys
sys.path.append('/home/kuangph/hf-starter')

def test_layer_specific_parameters():
    """æµ‹è¯•æ¯å±‚éƒ½æœ‰ç‹¬ç«‹çš„å‚æ•°å‘é‡ï¼Œé•¿åº¦ä¸å±‚ç´¢å¼•ç›¸å…³"""
    print("=== æµ‹è¯•æ¯å±‚ç‹¬ç«‹å‚æ•°è®¾è®¡ ===\n")
    
    head_dim = 64
    
    # æµ‹è¯•Method5åœ¨ä¸åŒå±‚çš„å‚æ•°å‘é‡é•¿åº¦
    print("Method5 - æ¯å±‚å‚æ•°å‘é‡é•¿åº¦æµ‹è¯•:")
    from models.version4.Method5_v4 import v4m5_ModifiedScailingComputation
    
    for layer_idx in range(5):
        method5 = v4m5_ModifiedScailingComputation(head_dim, layer_idx)
        expected_length = layer_idx + 1
        actual_length = len(method5.log_a_params)
        print(f"  ç¬¬{layer_idx}å±‚: æœŸæœ›å‚æ•°é•¿åº¦={expected_length}, å®é™…å‚æ•°é•¿åº¦={actual_length}, åŒ¹é…: {expected_length == actual_length}")
    print()
    
    # æµ‹è¯•Method6åœ¨ä¸åŒå±‚çš„å‚æ•°å‘é‡é•¿åº¦
    print("Method6 - æ¯å±‚å‚æ•°å‘é‡é•¿åº¦æµ‹è¯•:")
    from models.version4.Method6_v4 import v4m6_ModifiedScailingComputation
    
    for layer_idx in range(5):
        method6 = v4m6_ModifiedScailingComputation(head_dim, layer_idx)
        expected_length = layer_idx + 1
        actual_a_length = len(method6.log_a_params)
        actual_b_length = len(method6.b_params)
        print(f"  ç¬¬{layer_idx}å±‚: æœŸæœ›å‚æ•°é•¿åº¦={expected_length}, a_paramsé•¿åº¦={actual_a_length}, b_paramsé•¿åº¦={actual_b_length}")
        print(f"    åŒ¹é…: {expected_length == actual_a_length == actual_b_length}")
    print()
    
    # æµ‹è¯•Method7åœ¨ä¸åŒå±‚çš„å‚æ•°å‘é‡é•¿åº¦
    print("Method7 - æ¯å±‚å‚æ•°å‘é‡é•¿åº¦æµ‹è¯•:")
    from models.version4.Method7_v4 import v4m7_ModifiedScailingComputation
    
    for layer_idx in range(5):
        method7 = v4m7_ModifiedScailingComputation(head_dim, layer_idx)
        expected_length = layer_idx + 1
        actual_length = len(method7.log_a_params)
        print(f"  ç¬¬{layer_idx}å±‚: æœŸæœ›å‚æ•°é•¿åº¦={expected_length}, å®é™…å‚æ•°é•¿åº¦={actual_length}, åŒ¹é…: {expected_length == actual_length}")
    print()

def test_independence_between_layers():
    """æµ‹è¯•ä¸åŒå±‚çš„å‚æ•°ç¡®å®æ˜¯ç‹¬ç«‹çš„"""
    print("=== æµ‹è¯•å±‚é—´å‚æ•°ç‹¬ç«‹æ€§ ===\n")
    
    head_dim = 64
    
    # åˆ›å»ºä¸¤ä¸ªä¸åŒå±‚çš„Method5å®ä¾‹
    from models.version4.Method5_v4 import v4m5_ModifiedScailingComputation
    method5_layer1 = v4m5_ModifiedScailingComputation(head_dim, layer_idx=1)
    method5_layer2 = v4m5_ModifiedScailingComputation(head_dim, layer_idx=2)
    
    # ä¿®æ”¹ç¬¬1å±‚çš„å‚æ•°
    method5_layer1.log_a_params.data[0] = 1.0
    method5_layer1.log_a_params.data[1] = 2.0
    
    # ä¿®æ”¹ç¬¬2å±‚çš„å‚æ•°
    method5_layer2.log_a_params.data[0] = -1.0
    method5_layer2.log_a_params.data[1] = 0.0
    method5_layer2.log_a_params.data[2] = 1.0
    
    print("Method5 å±‚é—´å‚æ•°ç‹¬ç«‹æ€§æµ‹è¯•:")
    print(f"  ç¬¬1å±‚å‚æ•°: {method5_layer1.log_a_params.data.tolist()}")
    print(f"  ç¬¬2å±‚å‚æ•°: {method5_layer2.log_a_params.data.tolist()}")
    print(f"  å‚æ•°é•¿åº¦ä¸åŒ: {len(method5_layer1.log_a_params) != len(method5_layer2.log_a_params)}")
    print(f"  å‚æ•°å€¼ç‹¬ç«‹: {not torch.equal(method5_layer1.log_a_params.data[:2], method5_layer2.log_a_params.data[:2])}")
    print("  âœ“ å±‚é—´å‚æ•°ç¡®å®ç‹¬ç«‹\n")

def test_compute_scaling_with_correct_length():
    """æµ‹è¯•ç¼©æ”¾è®¡ç®—ä½¿ç”¨æ­£ç¡®é•¿åº¦çš„å‚æ•°å‘é‡"""
    print("=== æµ‹è¯•ç¼©æ”¾è®¡ç®—ä½¿ç”¨æ­£ç¡®é•¿åº¦çš„å‚æ•° ===\n")
    
    head_dim = 64
    
    # æµ‹è¯•ç¬¬3å±‚ï¼ˆåº”è¯¥æœ‰4ä¸ªå‚æ•°ï¼Œå¯¹åº”å±‚0,1,2,3çš„QKçŸ©é˜µï¼‰
    from models.version4.Method5_v4 import v4m5_ModifiedScailingComputation
    method5_layer3 = v4m5_ModifiedScailingComputation(head_dim, layer_idx=3)
    
    # è®¾ç½®ä¸åŒçš„å‚æ•°å€¼
    method5_layer3.log_a_params.data = torch.tensor([0.0, 1.0, -1.0, 0.5])
    
    # åˆ›å»º4ä¸ªQKçŸ©é˜µï¼ˆå¯¹åº”å‰4å±‚ï¼‰
    qk_matrices = [torch.randn(2, 8, 10, 10) for _ in range(4)]
    
    # è®¡ç®—ç¼©æ”¾
    result = method5_layer3.compute_modified_scaling(qk_matrices, 3)
    
    # æ‰‹åŠ¨éªŒè¯è®¡ç®—
    expected = torch.zeros_like(qk_matrices[-1])
    scaling_values = []
    
    for i in range(4):
        a_i = torch.exp(method5_layer3.log_a_params[i]).item()
        scaling = 1.0 / (a_i * math.sqrt(head_dim))
        scaling_values.append(scaling)
        expected += scaling * qk_matrices[i]
    
    print("Method5 ç¬¬3å±‚ç¼©æ”¾è®¡ç®—æµ‹è¯•:")
    print(f"  å‚æ•°å‘é‡é•¿åº¦: {len(method5_layer3.log_a_params)}")
    print(f"  QKçŸ©é˜µæ•°é‡: {len(qk_matrices)}")
    print(f"  ç¼©æ”¾å€¼: {[f'{v:.6f}' for v in scaling_values]}")
    print(f"  è®¡ç®—ç»“æœæ­£ç¡®: {torch.allclose(result, expected, atol=1e-6)}")
    print()

def test_layer_creation_in_attention():
    """æµ‹è¯•Attentionå±‚ä¸­ModifiedScalingComputationçš„æ­£ç¡®åˆ›å»º"""
    print("=== æµ‹è¯•Attentionå±‚ä¸­çš„æ­£ç¡®åˆ›å»º ===\n")
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„é…ç½®
    class DummyConfig:
        def __init__(self):
            self.hidden_size = 512
            self.num_attention_heads = 8
            self.num_key_value_heads = 8
            self.head_dim = self.hidden_size // self.num_attention_heads
            self.max_position_embeddings = 2048
            self.rope_theta = 10000.0
            self.attention_dropout = 0.0
            self.pretraining_tp = 1
    
    config = DummyConfig()
    
    # æµ‹è¯•ä¸åŒå±‚ç´¢å¼•çš„Attention
    from models.version4.Method5_v4 import Method5LlamaAttention_v4
    
    print("Method5 Attentionå±‚åˆ›å»ºæµ‹è¯•:")
    for layer_idx in range(4):
        attention = Method5LlamaAttention_v4(config, layer_idx=layer_idx)
        expected_param_length = layer_idx + 1
        actual_param_length = len(attention.modified_scaling.log_a_params)
        
        print(f"  ç¬¬{layer_idx}å±‚Attention: æœŸæœ›å‚æ•°é•¿åº¦={expected_param_length}, å®é™…={actual_param_length}, åŒ¹é…: {expected_param_length == actual_param_length}")
    
    print("  âœ“ Attentionå±‚ä¸­çš„ModifiedScalingComputationåˆ›å»ºæ­£ç¡®\n")

if __name__ == "__main__":
    test_layer_specific_parameters()
    test_independence_between_layers()
    test_compute_scaling_with_correct_length()
    test_layer_creation_in_attention()
    print("ğŸ‰ æ‰€æœ‰å±‚ç‹¬ç«‹å‚æ•°è®¾è®¡æµ‹è¯•éƒ½é€šè¿‡ï¼")
    print("\nğŸ“ æ€»ç»“:")
    print("- æ¯å±‚éƒ½æœ‰ç‹¬ç«‹çš„ModifiedScalingComputationå®ä¾‹")
    print("- æ¯å±‚çš„å‚æ•°å‘é‡é•¿åº¦ = layer_idx + 1")
    print("- ä¸éœ€è¦max_layerså‚æ•°ï¼Œé¿å…äº†å‚æ•°å…±äº«é—®é¢˜")
    print("- ç¬¬iå±‚ä½¿ç”¨å‰i+1å±‚çš„QK^TçŸ©é˜µï¼Œå¯¹åº”i+1ä¸ªç¼©æ”¾å‚æ•°")
