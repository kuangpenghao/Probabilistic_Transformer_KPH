#!/usr/bin/env python3
"""
è¯Šæ–­Version4æ–¹æ³•çš„å¯å­¦ä¹ å‚æ•°é—®é¢˜
"""

import torch
import sys
sys.path.append('/home/kuangph/hf-starter')

def diagnose_learnable_parameters():
    """è¯Šæ–­å¯å­¦ä¹ å‚æ•°æ˜¯å¦æ­£ç¡®æ³¨å†Œå’Œå‚ä¸è®­ç»ƒ"""
    print("=== Version4 å¯å­¦ä¹ å‚æ•°è¯Šæ–­ ===\n")
    
    methods_info = [
        ("Method4", "models.version4.Method4_v4", "Method4Config_v4", "Method4LlamaForCausalLM_v4"),
        ("Method5", "models.version4.Method5_v4", "Method5Config_v4", "Method5LlamaForCausalLM_v4"),
        ("Method6", "models.version4.Method6_v4", "Method6Config_v4", "Method6LlamaForCausalLM_v4"),
        ("Method7", "models.version4.Method7_v4", "Method7Config_v4", "Method7LlamaForCausalLM_v4"),
    ]
    
    all_issues = []
    
    for method_name, module_path, config_class_name, model_class_name in methods_info:
        try:
            print(f"ğŸ” è¯Šæ–­ {method_name}:")
            
            # åŠ¨æ€å¯¼å…¥
            module = __import__(module_path, fromlist=[config_class_name, model_class_name])
            config_class = getattr(module, config_class_name)
            model_class = getattr(module, model_class_name)
            
            # åˆ›å»ºå°å‹æµ‹è¯•é…ç½®
            config = config_class(
                vocab_size=1000,
                hidden_size=128,
                intermediate_size=256,
                num_hidden_layers=3,
                num_attention_heads=4,
                max_position_embeddings=512
            )
            
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            model = model_class(config)
            
            # 1. æ£€æŸ¥æ¨¡å‹çš„æ‰€æœ‰å‚æ•°
            all_params = list(model.parameters())
            total_params = sum(p.numel() for p in all_params)
            print(f"  ğŸ“Š æ¨¡å‹æ€»å‚æ•°æ•°: {total_params:,}")
            
            # 2. æŸ¥æ‰¾å¯å­¦ä¹ ç¼©æ”¾å‚æ•°
            scaling_params = []
            scaling_param_names = []
            
            for name, param in model.named_parameters():
                if any(keyword in name for keyword in ['modified_scaling', 'log_a_params', 'a_params', 'b_params', '.a', '.b']):
                    scaling_params.append(param)
                    scaling_param_names.append(name)
            
            print(f"  ğŸ¯ æ‰¾åˆ°ç¼©æ”¾å‚æ•°: {len(scaling_params)} ä¸ª")
            for name in scaling_param_names:
                print(f"    - {name}")
            
            if len(scaling_params) == 0:
                print("  âŒ ä¸¥é‡é—®é¢˜ï¼šæ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¼©æ”¾å‚æ•°ï¼")
                all_issues.append(f"{method_name}: æ²¡æœ‰æ‰¾åˆ°ç¼©æ”¾å‚æ•°")
                continue
            
            # 3. æ£€æŸ¥å‚æ•°æ˜¯å¦éœ€è¦æ¢¯åº¦
            requires_grad_count = sum(1 for p in scaling_params if p.requires_grad)
            print(f"  ğŸ”„ éœ€è¦æ¢¯åº¦çš„ç¼©æ”¾å‚æ•°: {requires_grad_count}/{len(scaling_params)}")
            
            if requires_grad_count != len(scaling_params):
                print("  âš ï¸  è­¦å‘Šï¼šéƒ¨åˆ†ç¼©æ”¾å‚æ•°ä¸éœ€è¦æ¢¯åº¦ï¼")
                all_issues.append(f"{method_name}: éƒ¨åˆ†å‚æ•°ä¸éœ€è¦æ¢¯åº¦")
            
            # 4. æ£€æŸ¥å‚æ•°åˆå§‹å€¼
            print("  ğŸ“‹ å‚æ•°åˆå§‹å€¼:")
            for name, param in zip(scaling_param_names, scaling_params):
                if param.numel() <= 10:  # åªæ˜¾ç¤ºå°å‚æ•°
                    print(f"    {name}: {param.data}")
                else:
                    print(f"    {name}: shape={param.shape}, mean={param.data.mean():.4f}")
            
            # 5. æ¨¡æ‹Ÿå‰å‘ä¼ æ’­ï¼Œæ£€æŸ¥å‚æ•°æ˜¯å¦å‚ä¸è®¡ç®—
            print("  ğŸ”„ æµ‹è¯•å‰å‘ä¼ æ’­...")
            
            # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
            batch_size, seq_len = 2, 10
            input_ids = torch.randint(0, config.vocab_size, (batch_size, seq_len))
            
            # è®¾ç½®æ¢¯åº¦è¿½è¸ª
            for param in scaling_params:
                param.requires_grad_(True)
            
            # å‰å‘ä¼ æ’­
            model.train()
            outputs = model(input_ids, labels=input_ids)
            loss = outputs.loss
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ£€æŸ¥æ¢¯åº¦
            grad_count = 0
            for name, param in zip(scaling_param_names, scaling_params):
                if param.grad is not None:
                    grad_count += 1
                    grad_norm = param.grad.norm().item()
                    print(f"    {name}: grad_norm={grad_norm:.6f}")
                else:
                    print(f"    {name}: âŒ æ²¡æœ‰æ¢¯åº¦ï¼")
            
            if grad_count == 0:
                print("  âŒ ä¸¥é‡é—®é¢˜ï¼šæ‰€æœ‰ç¼©æ”¾å‚æ•°éƒ½æ²¡æœ‰æ¢¯åº¦ï¼")
                all_issues.append(f"{method_name}: å‚æ•°æ²¡æœ‰å‚ä¸æ¢¯åº¦è®¡ç®—")
            elif grad_count < len(scaling_params):
                print("  âš ï¸  è­¦å‘Šï¼šéƒ¨åˆ†ç¼©æ”¾å‚æ•°æ²¡æœ‰æ¢¯åº¦ï¼")
                all_issues.append(f"{method_name}: éƒ¨åˆ†å‚æ•°æ²¡æœ‰æ¢¯åº¦")
            else:
                print("  âœ… æ‰€æœ‰ç¼©æ”¾å‚æ•°éƒ½æœ‰æ¢¯åº¦")
            
            # 6. æ£€æŸ¥å‚æ•°å€¼æ˜¯å¦ä¼šå˜åŒ–
            old_values = [p.data.clone() for p in scaling_params]
            
            # æ¨¡æ‹Ÿä¼˜åŒ–å™¨æ­¥éª¤
            optimizer = torch.optim.AdamW(scaling_params, lr=0.01)
            optimizer.step()
            
            changed_count = 0
            for i, (param, old_val) in enumerate(zip(scaling_params, old_values)):
                if not torch.equal(param.data, old_val):
                    changed_count += 1
            
            print(f"  ğŸ“ˆ ä¼˜åŒ–å™¨æ­¥éª¤åå˜åŒ–çš„å‚æ•°: {changed_count}/{len(scaling_params)}")
            
            if changed_count == 0:
                print("  âŒ ä¸¥é‡é—®é¢˜ï¼šä¼˜åŒ–å™¨æ­¥éª¤åå‚æ•°æ²¡æœ‰å˜åŒ–ï¼")
                all_issues.append(f"{method_name}: å‚æ•°ä¸ä¼šè¢«ä¼˜åŒ–å™¨æ›´æ–°")
            
            print("  âœ… å‚æ•°è¯Šæ–­å®Œæˆ\n")
                
        except Exception as e:
            print(f"  âŒ {method_name} è¯Šæ–­å¤±è´¥: {str(e)}")
            all_issues.append(f"{method_name}: è¯Šæ–­å¤±è´¥ - {str(e)}")
            print()
    
    # æ€»ç»“æŠ¥å‘Š
    print("=" * 60)
    print("ğŸ” è¯Šæ–­æ€»ç»“:")
    
    if not all_issues:
        print("ğŸ‰ æ‰€æœ‰æ–¹æ³•çš„å¯å­¦ä¹ å‚æ•°éƒ½å·¥ä½œæ­£å¸¸ï¼")
    else:
        print("âŒ å‘ç°ä»¥ä¸‹é—®é¢˜:")
        for issue in all_issues:
            print(f"  - {issue}")
        
        print("\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®æ³¨å†Œä¸ºnn.Parameter")
        print("2. æ£€æŸ¥forwardå‡½æ•°ä¸­æ˜¯å¦ä½¿ç”¨äº†è¿™äº›å‚æ•°")
        print("3. æ£€æŸ¥å‚æ•°æ˜¯å¦è¢«æ­£ç¡®ä¼ é€’åˆ°è®¡ç®—å›¾ä¸­")
        print("4. æ£€æŸ¥ä¼˜åŒ–å™¨æ˜¯å¦åŒ…å«äº†è¿™äº›å‚æ•°")
    
    return len(all_issues) == 0

if __name__ == "__main__":
    success = diagnose_learnable_parameters()
    if not success:
        print("\nğŸš¨ éœ€è¦ä¿®å¤å‚æ•°é—®é¢˜åæ‰èƒ½æ­£å¸¸è®­ç»ƒï¼")
    else:
        print("\nğŸš€ å¯å­¦ä¹ å‚æ•°è¯Šæ–­é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼")
