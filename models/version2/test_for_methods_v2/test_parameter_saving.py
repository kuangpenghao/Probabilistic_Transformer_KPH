#!/usr/bin/env python3
"""
æµ‹è¯•Method3_v2æƒé‡å‚æ•°ä¿å­˜åŠŸèƒ½
"""

import torch
import torch.nn.functional as F
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append('/home/kuangph/hf-starter')

from models.version2.Method3_v2 import Method3LlamaForCausalLM_v2, Method3Config_v2

def test_parameter_saving():
    """æµ‹è¯•æƒé‡å‚æ•°ä¿å­˜åŠŸèƒ½"""
    
    print("æµ‹è¯•æƒé‡å‚æ•°ä¿å­˜åŠŸèƒ½...")
    print("=" * 60)
    
    # åˆ›å»ºé…ç½®
    config = Method3Config_v2(
        hidden_size=64,
        intermediate_size=256,
        num_hidden_layers=4,
        num_attention_heads=8,
        vocab_size=1000
    )
    
    # åˆ›å»ºæ¨¡å‹
    model = Method3LlamaForCausalLM_v2(config)
    
    # æ¨¡æ‹Ÿè®­ç»ƒåçš„æƒé‡ï¼ˆæ‰‹åŠ¨è®¾ç½®ä¸€äº›ä¸åŒçš„æƒé‡å€¼ï¼‰
    print("è®¾ç½®æ¨¡æ‹Ÿçš„è®­ç»ƒåæƒé‡...")
    
    # è®¾ç½®ç¬¬1å±‚çš„æƒé‡
    if hasattr(model.model.layers[1], 'mlp_residual_weights'):
        model.model.layers[1].mlp_residual_weights.data = torch.tensor([1.5, 0.8])
        print(f"ç¬¬1å±‚æƒé‡: {model.model.layers[1].mlp_residual_weights.data}")
    
    # è®¾ç½®ç¬¬2å±‚çš„æƒé‡
    if hasattr(model.model.layers[2], 'mlp_residual_weights'):
        model.model.layers[2].mlp_residual_weights.data = torch.tensor([2.0, 1.0, 0.5])
        print(f"ç¬¬2å±‚æƒé‡: {model.model.layers[2].mlp_residual_weights.data}")
    
    # è®¾ç½®ç¬¬3å±‚çš„æƒé‡
    if hasattr(model.model.layers[3], 'mlp_residual_weights'):
        model.model.layers[3].mlp_residual_weights.data = torch.tensor([0.5, 1.5, 2.5, 1.2])
        print(f"ç¬¬3å±‚æƒé‡: {model.model.layers[3].mlp_residual_weights.data}")
    
    print("\nä¿å­˜æƒé‡å‚æ•°...")
    
    # ä¿å­˜æƒé‡å‚æ•°åˆ°å½“å‰ç›®å½•
    save_path = model.save_learned_parameters('/home/kuangph/hf-starter/models/version2')
    
    print(f"æƒé‡å‚æ•°å·²ä¿å­˜åˆ°: {save_path}")
    
    # éªŒè¯æ–‡ä»¶æ˜¯å¦åˆ›å»ºæˆåŠŸ
    if os.path.exists(save_path):
        print("âœ… æ–‡ä»¶åˆ›å»ºæˆåŠŸ!")
        
        # è¯»å–å¹¶æ˜¾ç¤ºæ–‡ä»¶å†…å®¹çš„å‰å‡ è¡Œ
        print("\næ–‡ä»¶å†…å®¹é¢„è§ˆ:")
        print("-" * 40)
        with open(save_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            for i, line in enumerate(lines[:20]):  # æ˜¾ç¤ºå‰20è¡Œ
                print(f"{i+1:2d}: {line.rstrip()}")
            if len(lines) > 20:
                print(f"... (æ–‡ä»¶å…±{len(lines)}è¡Œ)")
    else:
        print("âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥!")
    
    return save_path

def test_weight_analysis():
    """æµ‹è¯•æƒé‡åˆ†æåŠŸèƒ½"""
    
    print("\n\næµ‹è¯•æƒé‡åˆ†æåŠŸèƒ½...")
    print("=" * 60)
    
    # åˆ›å»ºé…ç½®
    config = Method3Config_v2(
        hidden_size=32,
        intermediate_size=128,
        num_hidden_layers=3,
        num_attention_heads=4,
        vocab_size=500
    )
    
    # åˆ›å»ºæ¨¡å‹
    model = Method3LlamaForCausalLM_v2(config)
    
    # è®¾ç½®ä¸€äº›æœ‰è¶£çš„æƒé‡æ¨¡å¼è¿›è¡Œåˆ†æ
    print("è®¾ç½®ä¸åŒçš„æƒé‡æ¨¡å¼...")
    
    # ç¬¬1å±‚ï¼šæ¯”è¾ƒå‡åŒ€çš„æƒé‡
    if hasattr(model.model.layers[1], 'mlp_residual_weights'):
        model.model.layers[1].mlp_residual_weights.data = torch.tensor([1.1, 0.9])
        print(f"ç¬¬1å±‚ (å‡åŒ€): {model.model.layers[1].mlp_residual_weights.data}")
    
    # ç¬¬2å±‚ï¼šæœ‰æ˜æ˜¾åå¥½çš„æƒé‡
    if hasattr(model.model.layers[2], 'mlp_residual_weights'):
        model.model.layers[2].mlp_residual_weights.data = torch.tensor([0.2, 3.0, 0.5])
        print(f"ç¬¬2å±‚ (åå¥½): {model.model.layers[2].mlp_residual_weights.data}")
    
    # ä¿å­˜å¹¶åˆ†æ
    save_path = model.save_learned_parameters('/home/kuangph/hf-starter/models/version2')
    
    print(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {save_path}")
    
    return save_path

if __name__ == "__main__":
    # æµ‹è¯•åŸºæœ¬ä¿å­˜åŠŸèƒ½
    save_path1 = test_parameter_saving()
    
    # æµ‹è¯•æƒé‡åˆ†æåŠŸèƒ½
    save_path2 = test_weight_analysis()
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print(f"å¯ä»¥æŸ¥çœ‹ä¿å­˜çš„æ–‡ä»¶: {save_path1}")
    print(f"å¯ä»¥æŸ¥çœ‹åˆ†ææ–‡ä»¶: {save_path2}")
