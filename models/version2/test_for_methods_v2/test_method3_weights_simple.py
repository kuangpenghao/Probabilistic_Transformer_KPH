#!/usr/bin/env python3
"""
ç®€åŒ–æµ‹è¯•ï¼šä¸“æ³¨äºå¯å­¦ä¹ æƒé‡å‚æ•°çš„æ ¸å¿ƒåŠŸèƒ½
"""

import torch
import torch.nn.functional as F
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append('/home/kuangph/hf-starter')

from models.version2.Method3_v2 import Method3DecoderLayer_v2, Method3Config_v2

def test_weights_functionality():
    """æµ‹è¯•æƒé‡å‚æ•°çš„æ ¸å¿ƒåŠŸèƒ½"""
    
    # åˆ›å»ºé…ç½®
    config = Method3Config_v2(
        hidden_size=64,
        intermediate_size=256,
        num_hidden_layers=4,
        num_attention_heads=8,
        vocab_size=1000
    )
    
    print("æµ‹è¯•å¯å­¦ä¹ æƒé‡å‚æ•°æ ¸å¿ƒåŠŸèƒ½...")
    print("=" * 50)
    
    # æµ‹è¯•ä¸åŒå±‚çš„æƒé‡å‚æ•°
    for layer_idx in range(4):
        layer = Method3DecoderLayer_v2(config, layer_idx=layer_idx)
        
        if layer_idx == 0:
            print(f"ç¬¬{layer_idx}å±‚: æƒé‡å‚æ•° = {layer.mlp_residual_weights}")
            assert layer.mlp_residual_weights is None
        else:
            print(f"ç¬¬{layer_idx}å±‚: æƒé‡å‚æ•°å½¢çŠ¶ = {layer.mlp_residual_weights.shape}")
            print(f"ç¬¬{layer_idx}å±‚: æƒé‡å‚æ•°å€¼ = {layer.mlp_residual_weights}")
            assert layer.mlp_residual_weights.shape == (layer_idx + 1,)
            
            # æµ‹è¯•æ¢¯åº¦
            assert layer.mlp_residual_weights.requires_grad == True
            
            # æµ‹è¯•å½’ä¸€åŒ–
            normalized = F.softmax(layer.mlp_residual_weights, dim=0)
            print(f"ç¬¬{layer_idx}å±‚: å½’ä¸€åŒ–æƒé‡ = {normalized}")
            print(f"ç¬¬{layer_idx}å±‚: æƒé‡æ€»å’Œ = {normalized.sum():.6f}")
            assert torch.allclose(normalized.sum(), torch.tensor(1.0))
        
        print("-" * 30)
    
    # æµ‹è¯•æƒé‡æ›´æ–°
    print("\næµ‹è¯•æƒé‡æ›´æ–°:")
    layer_2 = Method3DecoderLayer_v2(config, layer_idx=2)
    original_weights = layer_2.mlp_residual_weights.clone()
    
    # æ‰‹åŠ¨è®¾ç½®æƒé‡
    layer_2.mlp_residual_weights.data = torch.tensor([0.5, 2.0, 1.5])
    normalized = F.softmax(layer_2.mlp_residual_weights, dim=0)
    
    print(f"åŸå§‹æƒé‡: {original_weights}")
    print(f"æ›´æ–°åæƒé‡: {layer_2.mlp_residual_weights}")
    print(f"å½’ä¸€åŒ–æƒé‡: {normalized}")
    print(f"æƒé‡æ€»å’Œ: {normalized.sum():.6f}")
    
    # æµ‹è¯•æ¢¯åº¦è®¡ç®—
    print("\næµ‹è¯•æ¢¯åº¦è®¡ç®—:")
    dummy_target = torch.tensor([0.3, 0.5, 0.2])
    loss = F.mse_loss(normalized, dummy_target)
    loss.backward()
    
    print(f"æŸå¤±: {loss.item():.6f}")
    print(f"æƒé‡æ¢¯åº¦: {layer_2.mlp_residual_weights.grad}")
    
    print("\nâœ… æ‰€æœ‰æƒé‡åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")

def test_weighted_combination():
    """æµ‹è¯•åŠ æƒç»„åˆé€»è¾‘"""
    
    print("\næµ‹è¯•åŠ æƒç»„åˆé€»è¾‘...")
    print("=" * 50)
    
    # æ¨¡æ‹ŸMLPè¾“å‡º
    batch_size, seq_length, hidden_size = 2, 5, 64
    
    mlp_outputs = [
        torch.randn(batch_size, seq_length, hidden_size),  # ç¬¬0å±‚
        torch.randn(batch_size, seq_length, hidden_size),  # ç¬¬1å±‚
        torch.randn(batch_size, seq_length, hidden_size),  # ç¬¬2å±‚ (å½“å‰å±‚)
    ]
    
    # æƒé‡å‚æ•°
    weights = torch.tensor([1.0, 2.0, 0.5])  # æœªå½’ä¸€åŒ–
    normalized_weights = F.softmax(weights, dim=0)
    print(f"æƒé‡: {weights}")
    print(f"å½’ä¸€åŒ–æƒé‡: {normalized_weights}")
    
    # è®¡ç®—åŠ æƒå’Œ
    weighted_sum = torch.zeros_like(mlp_outputs[0])
    for i, output in enumerate(mlp_outputs):
        weighted_sum += normalized_weights[i] * output
        print(f"æƒé‡ {i}: {normalized_weights[i]:.4f}")
    
    print(f"è¾“å…¥å½¢çŠ¶: {[out.shape for out in mlp_outputs]}")
    print(f"åŠ æƒå’Œå½¢çŠ¶: {weighted_sum.shape}")
    
    # éªŒè¯åŠ æƒå’Œä¸æ˜¯ç®€å•çš„å¹³å‡
    simple_avg = sum(mlp_outputs) / len(mlp_outputs)
    
    print(f"æ˜¯å¦ä¸ç®€å•å¹³å‡ç›¸åŒ: {torch.allclose(weighted_sum, simple_avg)}")
    print(f"åŠ æƒå’ŒèŒƒæ•°: {torch.norm(weighted_sum):.4f}")
    print(f"ç®€å•å¹³å‡èŒƒæ•°: {torch.norm(simple_avg):.4f}")
    
    print("\nâœ… åŠ æƒç»„åˆæµ‹è¯•é€šè¿‡ï¼")

if __name__ == "__main__":
    test_weights_functionality()
    test_weighted_combination()
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼å¯å­¦ä¹ æƒé‡å‚æ•°åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼")
