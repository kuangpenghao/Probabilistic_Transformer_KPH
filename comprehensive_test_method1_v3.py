#!/usr/bin/env python3
import sys
import os
import torch
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_method1_v3():
    print("å¼€å§‹æµ‹è¯• Method1_v3...")
    
    try:
        from models.version3.configuration_llama_v3 import Method1Config_v3
        from models.version3.Method1_v3 import Method1LlamaForCausalLM_v3
        print("âœ“ æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºä¸€ä¸ªå°å‹é…ç½®ç”¨äºæµ‹è¯•
        config = Method1Config_v3(
            hidden_size=64,
            intermediate_size=128,
            num_hidden_layers=3,
            num_attention_heads=4,
            num_key_value_heads=4,
            vocab_size=1000,
            max_position_embeddings=512,
            rms_norm_eps=1e-6,
        )
        print("âœ“ é…ç½®åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæ¨¡å‹
        model = Method1LlamaForCausalLM_v3(config)
        model.eval()
        print("âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"æ¨¡å‹å±‚æ•°: {len(model.model.layers)}")
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        batch_size = 2
        seq_length = 10
        input_ids = torch.randint(0, config.vocab_size, (batch_size, seq_length))
        attention_mask = torch.ones(batch_size, seq_length)
        
        print("âœ“ æµ‹è¯•è¾“å…¥åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        with torch.no_grad():
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                output_attentions=False,
                output_hidden_states=False
            )
        
        print("âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"è¾“å‡ºlogits shape: {outputs.logits.shape}")
        print(f"é¢„æœŸshape: ({batch_size}, {seq_length}, {config.vocab_size})")
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        expected_shape = (batch_size, seq_length, config.vocab_size)
        assert outputs.logits.shape == expected_shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {outputs.logits.shape} vs {expected_shape}"
        print("âœ“ è¾“å‡ºå½¢çŠ¶éªŒè¯æˆåŠŸ")
        
        # æµ‹è¯•å¤šå±‚çš„MLPé‡è®¡ç®—æ˜¯å¦æ­£å¸¸å·¥ä½œ
        print("\næµ‹è¯•MLPé‡è®¡ç®—æœºåˆ¶...")
        
        # è·å–ä¸­é—´å±‚çš„è¾“å‡ºçŠ¶æ€ï¼ˆç”¨äºéªŒè¯é‡è®¡ç®—é€»è¾‘ï¼‰
        with torch.no_grad():
            outputs_with_hidden = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                output_hidden_states=True
            )
        
        print(f"âœ“ è·å¾— {len(outputs_with_hidden.hidden_states)} å±‚çš„hidden states")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Method1_v3 å®ç°æ­£ç¡®ï¼")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_method1_v3()
    if success:
        print("\nâœ… Method1_v3 å®ç°æµ‹è¯•å®Œæˆï¼Œæ‰€æœ‰åŠŸèƒ½æ­£å¸¸ï¼")
    else:
        print("\nâŒ Method1_v3 å®ç°å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚")
